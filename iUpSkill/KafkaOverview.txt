https://app.pluralsight.com/player?course=apache-kafka-getting-started&author=ryan-plant&name=apache-kafka-getting-started-m0&clip=0&mode=live
--------------------------------------------------------------------------------
-What is Apache Kafka?
	A high-throughput distributed messaging system.
-Database replication
-Log shipping
-Extract, Transform,and Load (ETL)
-Messaging
-Custom middle ware magic
-Extract,Transform and Load (ETL)
	Typically proprietary and costly
	Lots of custom development
	Scalability challenged
	Performance challenged
	Often time requires multiple instances
-Middle ware Challenges
	Multi-write pattern
	Message broker pattern
-Apache Kafka Next-generation Messaging Goals
	High throughput
	Horizontally scalable
	Reliable and durable
	Loosely coupled Producers and Consumers
	Flexible publish-subscribe semantics
-Summary
	Kafka is a distributed messaging system
	Designed to move data at high volumes
	Addresses shortcomings of traditional data movement tools and approaches
	Invented by LinkedIn to address data growth issues common to many enterprises
	Open-sources under Apache Software Foundation in 2012
	First-choice adoption for data movement for hundreds of enterprise and internet-scale companies
-Getting to know Apache Kafka's Architecture
-Distributed Systems
	Collection of resources that are instructed to achieve a specific goal or function
	Consist of multiple workers or nodes.
	The system of nodes require coordination to ensure consistency and progress towards a common goal
	Each node communicates with each other though messages
-Reliable work distribution	 
-Distributed Systems : Communication and Consensus
	Worker node membership and naming 
	Configuration management
	Leader election
	Health status
-Apache Zookeeper
	Centralized service for maintaining metadata about a cluster of distributed nodes
		Configuration information
		Health status
		Group membership
		Hadoop,Hbase,Mesos,Solr,Redis and Neo4j
		Distributed system consisting of multiple nodes in an ensemble
-Summary
	Apache Kafka is a pub-sub messaging system, consisting of:
		Producers and ConsumersBrokers within a Cluster
	Characteristics of distributed system
		Worker node roles :Controllers,Leaders and Followers
		Reliability through replication
		Consensus-based communication
	Role of Apache Zookeeper
-Understanding Topics , Partitions and Brokers
-Event Sourcing
	An architectural style or approach to maintaining an application's state by capturing all changes as a sequence of time-ordered immutable events.
-Kafka Message Content
	Each message has a : 
		Timestamp
		Reference identifier
		Payload(binary)
-Apache kafka is publish-subscribe messaging rethought as a distributed commit log. 
-Creating a Topic : Single Partition
	$ bin/kafka-topics.sh --create --topic --topic my_topic \
	--zookeeper localhost:2181 \
	--partitions 1 \
	--replication-factor 1
-In general the scalability of Apache Kafka is determined by the number of partitions being managed by multiple broker nodes.
-Partitioning Trade-offs
	The more partitions the greater the Zookeeper overhead
		With large partition numbers ensure proper ZK capacity
	Message ordering can become complex
		Single partition for global ordering
		COnsumer-handling for ordering
	The more partition the longer the leader fail-over time
-Summary
	Detailed explanation of
		Topics and Partitions
		Broker partition management and behavior
	Aligned with distributed systems principles
		Broker leader election for partitions
		Work distribution and fail-over
	Kafka in action
		Demos
	Foundation upon which to dice deeper into Producers and Consumers
-Producing Messages with Kafka Producers
	Properties props  = new Properties();
	props.put("bootstrap.servers", "BROKER-1:9092, BROKER-2:9093");
	props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerilizer");
	props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
	KafkaProducer instances can only send ProducerRecords that match the key and value serializers types it is configured with.
	ProducerRecord : Optional Properties
	partition :
		specific partition within the topic to send ProducerRecord
	timestamp : 
		the unix timestamp applied to the records
	Best Practice : Define a key
		Two useful purposes
			Additional information in the message
			Can determine what partitions the message will be written to
		Downside
			Additional overhead
			Depends on the serializer type used
-Micro-batching in Apache Kafka
	At scale , efficiency is everything
	Small, fast batches of messages:
		Sending(Producer)
		Writing(Broker)
		Reading(Consumer)
	Modern operating system functions
		Pagecache
		Linux sendfile() system call (kernel)
	Amortzation of the constant cost
-Ordering Guarantees
	Message order by partition
		No global order across partitions
	Can get complicated with errors
		retries,retry.backoff.ms
		max.in.flight.request.per.connection
	Delivery semantics
		At-most-once, at-least-once, only-once
-Advance Topics Not Covered
	Custom Serializers
	Custom Partitioners
	Asynchronous Send
	Compression
	Advance Settings
-Summary
	Properties -> ProducerConfig
	Message -> ProducerRecord
	Processing Pipeline : Serializers and Partitioners
	Micro-batching -> Record Accumulator and RecordBuffer
	Delivery and Ordering Guarantees
-subscribe()
	For topics (dynamic/automatic)
	One topic,one-to-many partitions
	Many topics, many more partitions
	assign()
		For partitions
		One or more partitions, regardless of topic
		Manual, self-administering mode
-The Poll Loop
	Primary fucntions of the kafka Consumer
		-poll()
	Continuously polling the brokers for data
	Single API for handling all Consumer-Broker interactions
		A lot of interactions beyond message retrieval
-Kafka Consumer Polling
	The poll() process is a single-threaded operation
-The extent in which your system can be tolerant of eventually consistency is determined by its reliability.
-Offset Behavior
	Read != Committed
	Offset commit behavior is configurable
		-enable.auto.commit = true (default)
		-auto.commit.interval.ms = 5000 (default)
		-auto.offset.reset = "latest" (default)
			-"earliest"
			-"none"
	Single Consumer vs. Consumer Group
-commitSync
	Synchronous
	blocks until receives response from cluster
-commitAsync
	non-blocking but non-deterministic
-COnsumer groups
	kafka's solutions to COnsumer-side scale-out
	Independent Consumers working as a team
		group.id setting
	Sharing the message consumption and processing load
		-Parallelism and throughput
		-Redundancy
		-Performance
-Demo: Consumer Groups
	Consumer Group comprising of Java-based Consumer applications
	Setup:
		Three Consumers with same group id
		Consuming a single topic with three partitions
	Look for:
		Shared topic consumption
		Adding an additional Consumer
		Adding an additional topic
		Forcing a re balance
-Summary
	Kafka Consumer Internals
		Properties -> ConsumerConfig
		Message -> ConsumerRecord
		Subscriptions and assignments
		Message polling and consumption
		Offset management
	Consumer Groups
	Consumer Configuration
	Java-based Consumer
-Exploring the Kafka Ecosystem and Its Future
	Kafka Schema Registry
		Apache Avro serialization format
		First-class Avro serializers and de-serializers
		Schema registry and version management
		RESTful service discovery
		Compatibility broker
	Apache Kakfka Connect
		Common framework for integration
			Standardization of common approaches
			Producers and Consumers
		Platform Connectors
			Oracle,HP etc
		Connector Hub
-Challenges with Fast Data
	Apache STORM
	Apache SPARK
	Apache CASSANDRA
	Apache HADOOP
-kafka Streams
	Leverages existing Kafka machinery
	Single infrastructure solution
		At least for streaming-based processing
	Embeddable within existing applications
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-